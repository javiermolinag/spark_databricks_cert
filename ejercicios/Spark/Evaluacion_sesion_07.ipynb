{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38577af2-d648-4b03-82b5-f44adadae9b0",
   "metadata": {},
   "source": [
    "#### El cliente ha pedido realizar un ajuste a las reglas implementadas hasta ahora, estos ajustes consisten en reemplazar algunas funciones hechas con groupBy por funciones Window, presta mucha atención y resuelve las siguientes actividades.\n",
    "\n",
    "##### Nota: Para poder trabajar con este notebook es necesario haber terminado el ejercicio de las sesiones 04, 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2d536-bea9-4030-ab97-ab1bc50a83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML <style>pre { white-space: pre !important; }</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5e3c8-5689-4c7c-83d3-ec7b70d0e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame, Column, Row}\n",
    "import org.apache.spark.sql.{functions => f}\n",
    "import org.apache.spark.sql.{types => t}\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "def difference(l1: Seq[String], l2: Seq[String]): Seq[Column] =\n",
    "    l1.diff(l2).map(colName => f.col(colName))\n",
    "\n",
    "def readTmpDf(dfSeq: Seq[String]): Map[String, DataFrame] =\n",
    "    dfSeq.map(table_name => (table_name, spark.read.parquet(\"../../resources/data/tmp/parquet/\" + table_name))).toMap\n",
    "\n",
    "def writeTmpDf(dfSeq: Seq[(DataFrame, String)]): Unit = \n",
    "    dfSeq.foreach{case (df: DataFrame, name: String) => df.write.mode(\"overwrite\").parquet(\"../../resources/data/tmp/parquet/\" + name)}\n",
    "\n",
    "def schema_to_ddl(df: DataFrame): String = df.schema.toDDL.replace(\" NOT NULL\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f34787-67c5-4d2b-a592-4f29e250e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "\n",
    "// Creación de sesión de Spark\n",
    "val spark = SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"ejercicio_7\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT-6\")\n",
    "\n",
    "// Carga de tablas requeridas\n",
    "val RootPath = \"../../resources/data/tmp/parquet/\"\n",
    "val namesList = Seq(\"04/movies\", \"04/ratings\", \"04/tags\")\n",
    "val dfMap = readTmpDf(namesList)\n",
    "\n",
    "val moviesDf = dfMap(\"04/movies\")\n",
    "val ratingsDf = dfMap(\"04/ratings\")\n",
    "val tagsDf = dfMap(\"04/tags\")\n",
    "\n",
    "moviesDf.show(1, false)\n",
    "ratingsDf.show(1)\n",
    "tagsDf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07f716-9806-4388-ad1a-b0fa9f4266cf",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO ->    En esta actividad hay que resolver la logica que implementaste en la \"Actividad 2 de la sesión 07 - método calculate_rating_values\" pero reemplazando el uso de la función groupBy por funciones Window. \n",
    "##### Tendrás que obtener el mismo resultado ya que en las validaciones se compararán ambos dataframes.\n",
    "##### La firma a utilizar es la siguiente:\n",
    "- ##### def calculateRatingValuesW(df: DataFrame): DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5bb862-0181-4a7e-86bd-1611fe915f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "def calculateRatingValuesW(df: DataFrame) -> DataFrame = \n",
    "    df // ratingsDf modificar codigo interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f75654c-f84e-4c13-83f2-445301d53f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "calculateRatingValuesW(ratingsDf).show(2)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada:\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "|  100062|      3.63|         0.83|          64|2014-03-11 21:23:33|\n",
    "|  100070|      3.54|         0.89|          13|2013-01-24 11:24:50|\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec544e2-6d98-427f-a16a-f74588d26ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val ratingValuesDf = calculateRatingValuesW(ratingsDf)\n",
    "\n",
    "assert(ratingValuesDf.isInstanceOf[DataFrame])\n",
    "assert(ratingValuesDf.columns.size == 5)\n",
    "assert(ratingValuesDf.count() == 83239)\n",
    "\n",
    "val data = ratingValuesDf\n",
    "    .select(f.col(\"movie_id\"),\n",
    "            f.col(\"avg_rating\").cast(t.DoubleType), \n",
    "            f.col(\"stddev_rating\").cast(t.DoubleType),\n",
    "            f.col(\"count_rating\").cast(t.LongType),\n",
    "            f.col(\"min_time_rating\").cast(t.StringType))\n",
    "    .filter(f.col(\"movie_id\") === \"296\")\n",
    "    .collect()(0)\n",
    "\n",
    "assert(data.getAs[String](\"movie_id\") == \"296\")\n",
    "assert(data.getAs[Double](\"avg_rating\") == 4.19)\n",
    "assert(data.getAs[Double](\"stddev_rating\") == 0.95)\n",
    "assert(data.getAs[Long](\"count_rating\") == 108756)\n",
    "assert(data.getAs[String](\"min_time_rating\") == \"1996-02-29 10:48:44\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c32fa-def0-4176-8d5e-50cf3358a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((ratingValuesDf, \"07/ratings\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7f23a-b777-44d4-ae7e-fe6308e6a8c1",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO ->    En esta actividad hay que resolver la logica que implementaste en la \"Actividad 3 de la sesión 07 - métodos getAct3Df1 y getAct3Df2\" pero reemplazando el uso de la función groupBy por funciones Window. \n",
    "##### Tendrás que obtener el mismo resultado ya que en las validaciones se compararán ambos dataframes.\n",
    "##### La firma a utilizar es la siguiente:\n",
    "- ##### Primer tabla (utilizando función concat_ws o concat): def getAct3Df1W(df: DataFrame) -> DataFrame:\n",
    "- ##### Segunda tabla (utilizando función struct): def getAct3Df2W(df: DataFrame) -> DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c013c1e-f140-45b1-ba93-336aef9acedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA, PUEDES GENERAR MÉTODOS O VARIABLES NUEVAS SI ASI LO REQUIERES\n",
    "\n",
    "def getAct3Df1W(df: DataFrame): DataFrame =\n",
    "    df // ... transformaciones a tagsDf\n",
    "\n",
    "def getAct3Df2W(df: DataFrame): DataFrame =\n",
    "    df // ... transformaciones a tagsDf\n",
    "\n",
    "val act3Df1 = getAct3Df1W(tagsDf)\n",
    "val act3Df2 = getAct3Df2W(tagsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76900e-7ba9-4d99-bb20-2540cca7d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "act3Df1.show(2, false)\n",
    "act3Df2.show(2, false)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada:\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "|movie_id|tag_count                                                         |min_time_tag       |\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "|100062  |[FATE : 1, PRESS-GANGED : 1, WAR : 1, WORLD WAR II : 1]           |2018-05-26 16:40:54|\n",
    "|100070  |[COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1]|2017-05-19 17:17:36|\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "|movie_id|tag_count                                                             |min_time_tag       |\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "|100062  |[{FATE, 1}, {PRESS-GANGED, 1}, {WAR, 1}, {WORLD WAR II, 1}]           |2018-05-26 16:40:54|\n",
    "|100070  |[{COMEDIAN, 2}, {COMEDY, 1}, {GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}]|2017-05-19 17:17:36|\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229650b4-a2d1-4c52-82e5-576defdfbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val expectedValueDf1 = Seq(Row(\"100070\",\n",
    "                               List(\"COMEDIAN : 2\",\n",
    "                                    \"COMEDY : 1\",\n",
    "                                    \"GOOD HUMOUR : 1\",\n",
    "                                    \"STRUGGLING CAREER : 1\"),\n",
    "                               \"2017-05-19 17:17:36.0\"))\n",
    "val schemaDf1 = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StringType)),\n",
    "    t.StructField(\"min_time_tag\", t.StringType)\n",
    "))\n",
    "assert(act3Df1.columns.size == 3)\n",
    "assert(act3Df1.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(act3Df1.columns.toSeq.contains(\"tag_count\"))\n",
    "assert(act3Df1.columns.toSeq.contains(\"min_time_tag\"))\n",
    "assert(schema_to_ddl(act3Df1.select(\"movie_id\", \"tag_count\", \"min_time_tag\")) == \"movie_id STRING,tag_count ARRAY<STRING>,min_time_tag TIMESTAMP\")\n",
    "assert(act3Df1.count() == 53452)\n",
    "val testDf1 = spark.createDataFrame(spark.sparkContext.parallelize(expectedValueDf1), schemaDf1)\n",
    "    .withColumn(\"min_time_tag\", f.col(\"min_time_tag\").cast(t.TimestampType))\n",
    "assert(act3Df1.select(\"movie_id\", \"tag_count\", \"min_time_tag\").filter(f.col(\"movie_id\") === \"100070\").except(testDf1).count() == 0)\n",
    "\n",
    "val expectedValueDf2 = Seq(Row(\"100070\",\n",
    "                               List(Row(\"COMEDIAN\",2L),\n",
    "                                    Row(\"COMEDY\",1L),\n",
    "                                    Row(\"GOOD HUMOUR\",1L),\n",
    "                                    Row(\"STRUGGLING CAREER\",1L)),\n",
    "                               \"2017-05-19 17:17:36.0\"))\n",
    "val schemaDf2 = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType(Seq(\n",
    "        t.StructField(\"tag\", t.StringType),\n",
    "        t.StructField(\"count\", t.LongType)\n",
    "    )))),\n",
    "    t.StructField(\"min_time_tag\", t.StringType)\n",
    "))\n",
    "assert(act3Df2.columns.size == 3)\n",
    "assert(act3Df2.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(act3Df2.columns.toSeq.contains(\"tag_count\"))\n",
    "assert(act3Df2.columns.toSeq.contains(\"min_time_tag\"))\n",
    "assert(schema_to_ddl(act3Df2.select(\"movie_id\", \"tag_count\", \"min_time_tag\")) == \"movie_id STRING,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>>,min_time_tag TIMESTAMP\")\n",
    "assert(act3Df2.count() == 53452)\n",
    "val testDf2 = spark.createDataFrame(spark.sparkContext.parallelize(expectedValueDf2), schemaDf2)\n",
    "    .withColumn(\"min_time_tag\", f.col(\"min_time_tag\").cast(t.TimestampType))\n",
    "assert(act3Df2.select(\"movie_id\", \"tag_count\", \"min_time_tag\").filter(f.col(\"movie_id\") === \"100070\").except(testDf2).count() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328bd3f-1e6b-4ab7-950c-22e4904f07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((act3Df1, \"07/tags_p1\"),\n",
    "              (act3Df2, \"07/tags_p2\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf84ab-0b94-4dc6-829e-b683e337b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val lastMoviesDf = moviesDf\n",
    "    .join(act3Df2, Seq(\"movie_id\"), \"left\")\n",
    "    .join(ratingValuesDf, Seq(\"movie_id\"), \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea21abfb-d225-4147-8a5f-7aad1afbbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((lastMoviesDf, \"07/movies\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7747f5-bf41-4a4d-a775-90cc9c75455a",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO ->    La última actividad a realizar es la siguiente:\n",
    "- ##### El cliente nos ha solicitado generar una tabla donde se muestre el top de peliculas ranqueadas por genero, para realizar esto se realizan los siguientes pasos:\n",
    "    - ##### Las peliculas que entran a la parte del ranqueo deben cumplir con las siguientes condiciones:\n",
    "        -  count_rating > 1000\n",
    "        -  avg_rating >= 4.2\n",
    "        -  stddev_rating < 2\n",
    "    - #####  Descomponer la columna \"genres\" en una columna llamada \"genre\"\n",
    "    - ##### Agregar la columna \"top\" donde se asignará el valor de la función \"rank\" de Spark tomando las siguientes caracteristicas:\n",
    "        - particionar por: \"genre\"\n",
    "        - order por: avg_rating DESC, stddev_rating ASC, count_rating DESC\n",
    "##### El esquema resultante deberá ser:\n",
    "* |-- title: string\n",
    "* |-- year: integer\n",
    "* |-- genre: string\n",
    "* |-- top: integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f3657-54ba-4b2a-a139-1ba41daa8b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "val topMoviesDf = lastMoviesDf // Transformaciones a lastMoviesDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250478e-7fff-4384-bbbf-9ae81599285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "topMoviesDf.show(5)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada (hay que mantener mismo orden de columnas):\n",
    "+--------------------+----+---------+---+\n",
    "|               title|year|    genre|top|\n",
    "+--------------------+----+---------+---+\n",
    "|Band of Brothers ...|2001|   Action|  1|\n",
    "|Seven Samurai (Sh...|1954|   Action|  2|\n",
    "|   Fight Club (1999)|1999|   Action|  3|\n",
    "|Over the Garden W...|2013|Adventure|  1|\n",
    "|Seven Samurai (Sh...|1954|Adventure|  2|\n",
    "+--------------------+----+---------+---+\n",
    "only showing top 5 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d5a52-1f1a-4ade-ba04-41266a276ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "val expectedTopMovies = Seq(\n",
    "    Row(\"Band of Brothers (2001)\", 2001, \"Action\", 1),\n",
    "    Row(\"Seven Samurai (Shichinin no samurai) (1954)\", 1954, \"Action\", 2),\n",
    "    Row(\"Fight Club (1999)\", 1999, \"Action\", 3),\n",
    "    Row(\"Over the Garden Wall (2013)\", 2013, \"Adventure\", 1),\n",
    "    Row(\"Seven Samurai (Shichinin no samurai) (1954)\", 1954, \"Adventure\", 2),\n",
    "    Row(\"Spirited Away (Sen to Chihiro no kamikakushi) (2001)\", 2001, \"Adventure\", 3),\n",
    "    Row(\"Over the Garden Wall (2013)\", 2013, \"Animation\", 1),\n",
    "    Row(\"Spirited Away (Sen to Chihiro no kamikakushi) (2001)\", 2001, \"Animation\", 2),\n",
    "    Row(\"Parasite (2019)\", 2019, \"Comedy\", 1),\n",
    "    Row(\"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\", 1964, \"Comedy\", 2),\n",
    "    Row(\"Shawshank Redemption, The (1994)\", 1994, \"Crime\", 1),\n",
    "    Row(\"Godfather, The (1972)\", 1972, \"Crime\", 2),\n",
    "    Row(\"Usual Suspects, The (1995)\", 1995, \"Crime\", 3),\n",
    "    Row(\"Godfather: Part II, The (1974)\", 1974, \"Crime\", 4),\n",
    "    Row(\"Fight Club (1999)\", 1999, \"Crime\", 5),\n",
    "    Row(\"Planet Earth (2006)\", 2006, \"Documentary\", 1),\n",
    "    Row(\"Planet Earth II (2016)\", 2016, \"Documentary\", 2),\n",
    "    Row(\"Blue Planet II (2017)\", 2017, \"Documentary\", 3),\n",
    "    Row(\"The Blue Planet (2001)\", 2001, \"Documentary\", 4),\n",
    "    Row(\"Shawshank Redemption, The (1994)\", 1994, \"Drama\", 1),\n",
    "    Row(\"Band of Brothers (2001)\", 2001, \"Drama\", 2),\n",
    "    Row(\"Parasite (2019)\", 2019, \"Drama\", 3),\n",
    "    Row(\"Godfather, The (1972)\", 1972, \"Drama\", 4),\n",
    "    Row(\"Twin Peaks (1989)\", 1989, \"Drama\", 5),\n",
    "    Row(\"12 Angry Men (1957)\", 1957, \"Drama\", 6),\n",
    "    Row(\"Godfather: Part II, The (1974)\", 1974, \"Drama\", 7),\n",
    "    Row(\"Over the Garden Wall (2013)\", 2013, \"Drama\", 8),\n",
    "    Row(\"Seven Samurai (Shichinin no samurai) (1954)\", 1954, \"Drama\", 9),\n",
    "    Row(\"Fight Club (1999)\", 1999, \"Drama\", 10),\n",
    "    Row(\"Schindler's List (1993)\", 1993, \"Drama\", 11),\n",
    "    Row(\"One Flew Over the Cuckoo's Nest (1975)\", 1975, \"Drama\", 12),\n",
    "    Row(\"Lives of Others, The (Das leben der Anderen) (2006)\", 2006, \"Drama\", 13),\n",
    "    Row(\"Casablanca (1942)\", 1942, \"Drama\", 14),\n",
    "    Row(\"Spirited Away (Sen to Chihiro no kamikakushi) (2001)\", 2001, \"Fantasy\", 1),\n",
    "    Row(\"Twin Peaks (1989)\", 1989, \"Mystery\", 1),\n",
    "    Row(\"Usual Suspects, The (1995)\", 1995, \"Mystery\", 2),\n",
    "    Row(\"Rear Window (1954)\", 1954, \"Mystery\", 3),\n",
    "    Row(\"Lives of Others, The (Das leben der Anderen) (2006)\", 2006, \"Romance\", 1),\n",
    "    Row(\"Casablanca (1942)\", 1942, \"Romance\", 2),\n",
    "    Row(\"Usual Suspects, The (1995)\", 1995, \"Thriller\", 1),\n",
    "    Row(\"Fight Club (1999)\", 1999, \"Thriller\", 2),\n",
    "    Row(\"Rear Window (1954)\", 1954, \"Thriller\", 3),\n",
    "    Row(\"Lives of Others, The (Das leben der Anderen) (2006)\", 2006, \"Thriller\", 4),\n",
    "    Row(\"Band of Brothers (2001)\", 2001, \"War\", 1),\n",
    "    Row(\"Schindler's List (1993)\", 1993, \"War\", 2),\n",
    "    Row(\"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\", 1964, \"War\", 3)\n",
    ")\n",
    "\n",
    "topMoviesDf\n",
    "    .select(f.col(\"title\"),f.col(\"year\").cast(t.IntegerType),f.col(\"genre\"),f.col(\"top\").cast(t.IntegerType))\n",
    "    .orderBy(f.col(\"genre\").asc, f.col(\"top\").asc)\n",
    "    .collect()\n",
    "    .zip(expectedTopMovies)\n",
    "    .foreach(tuple => {\n",
    "        assert(tuple._1.getAs[String](\"title\") == tuple._2.getAs[String](0))\n",
    "        assert(tuple._1.getAs[Int](\"year\") == tuple._2.getAs[Int](1))\n",
    "        assert(tuple._1.getAs[String](\"genre\") == tuple._2.getAs[String](2))\n",
    "        assert(tuple._1.getAs[Int](\"top\") == tuple._2.getAs[Int](3))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6c8bf-1fc0-40f7-8d4d-9711e0ec36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((topMoviesDf, \"07/top_movies\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fa97f-2ff6-4072-81ed-11585ed14096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
