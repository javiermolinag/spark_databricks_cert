{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38577af2-d648-4b03-82b5-f44adadae9b0",
   "metadata": {},
   "source": [
    "#### Hasta este punto tenemos nuestras tablas procesadas (movies, ratings y tags) de forma correcta. El cliente nos ha solicitado apoyar al departamento de Marketing a realizar algunas consultas y a generar una única tabla y realizar algunos ajustes a la tabla final antes de poder almacenarla.\n",
    "\n",
    "##### Nota: Para poder trabajar con este notebook es necesario haber terminado el ejercicio de la sesión 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5e3c8-5689-4c7c-83d3-ec7b70d0e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "%run utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f34787-67c5-4d2b-a592-4f29e250e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "from pyspark.sql import SparkSession, DataFrame, Column\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "\n",
    "# Creación de sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"ejercicio_8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Carga de tablas requeridas\n",
    "root_path = \"../resources/data/tmp/parquet/\"\n",
    "names_list = [\"05/movies\", \"05/ratings\", \"05/tags_p2\"]\n",
    "df_dict = read_tmp_df(spark, names_list)\n",
    "\n",
    "movies_df = df_dict[\"05/movies\"]\n",
    "ratings_df = df_dict[\"05/ratings\"]\n",
    "tags_df = df_dict[\"05/tags_p2\"]\n",
    "\n",
    "movies_df.show(1, False)\n",
    "ratings_df.show(1, False)\n",
    "tags_df.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71d4d1-826a-4993-bc6e-ee87939e3525",
   "metadata": {},
   "source": [
    "#### En la siguiente imagen se muestra una representación a traves del diagrama de Venn sobre cada tabla (movies_df, ratings_df y tags_df) la cual fue contruida por el departamento de Marketing, el problema es que no saben la cantidad de datos de cada conjunto.\n",
    "##### El cliente nos han solicitado obtener la cantidad de registros de cada conjunto de datos representado por las siguientes letras:\n",
    "- ##### A: Registros de movies_df que no tiene filas coincidentes con las tablas ratings_df y tags_df\n",
    "- ##### B: Registros de ratings_df que no tiene filas coincidentes con las tablas movies_df y tags_df\n",
    "- ##### C: Registros de tags_df que no tiene filas coincidentes con las tablas movies_df y ratings_df\n",
    "- ##### D: Registros de movies_df y ratings_df que no tiene filas coincidentes con la tabla tags_df\n",
    "- ##### E: Registros de movies_df y tags_df que no tiene filas coincidentes con la tabla ratings_df\n",
    "- ##### F: Registros de ratings_df y tags_df que no tiene filas coincidentes con la tabla movies_df\n",
    "- ##### G: Registros que contiene datos coincidentes en las tablas movies_df, ratings_df y tags_df\n",
    "-  Una tabla tiene registros coincidentes con otra cuando comparten el mismo valor en la columna \"movie_id\"\n",
    "\n",
    "![title](../../resources/img/Tablas_conjuntos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07f716-9806-4388-ad1a-b0fa9f4266cf",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO ->    Obtener los conjuntos de datos listados en el diagrama de Venn con operaciones de tipo join, con la finalidad de ahorrar recursos el cliente nos ha solicitado que en la salida de cada transformación el dataframe resultante contenga únicamente la columna \"movie_id\" (basta con utilizar únicante una trasnsformación select al inicio de las operaciones join y utilizar únicamente joins del tipo **left_semi** y **left_anti**).\n",
    "- ##### Los dataframes resultantes se almacenarán en las siguientes variables:\n",
    "    - ##### A_df -> Conjunto A\n",
    "    - ##### B_df -> Conjunto B\n",
    "    - ##### C_df -> Conjunto C\n",
    "    - ##### D_df -> Conjunto D\n",
    "    - ##### E_df -> Conjunto E\n",
    "    - ##### F_df -> Conjunto F\n",
    "    - ##### G_df -> Conjunto G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5bb862-0181-4a7e-86bd-1611fe915f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "# Conjunto A:\n",
    "Adf = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto B:\n",
    "Bdf = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto C:\n",
    "Cdf = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto D:\n",
    "Ddf = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto E:\n",
    "Edf = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto F:\n",
    "Fdf = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto G:\n",
    "Gdf = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f75654c-f84e-4c13-83f2-445301d53f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "B_df.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida de cada dataframe (desde A hasta G):\n",
    "+--------+\n",
    "|movie_id|\n",
    "+--------+\n",
    "|  179995|\n",
    "+--------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec544e2-6d98-427f-a16a-f74588d26ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "assert A_df.count() == 0\n",
    "assert B_df.count() == 4270\n",
    "assert C_df.count() == 539\n",
    "assert D_df.count() == 28815\n",
    "assert E_df.count() == 2759\n",
    "assert F_df.count() == 2251\n",
    "assert G_df.count() == 47903\n",
    "\n",
    "assert len(A_df.columns) == 1\n",
    "assert len(B_df.columns) == 1\n",
    "assert len(C_df.columns) == 1\n",
    "assert len(D_df.columns) == 1\n",
    "assert len(E_df.columns) == 1\n",
    "assert len(F_df.columns) == 1\n",
    "assert len(G_df.columns) == 1\n",
    "\n",
    "assert \"movie_id\" in A_df.columns\n",
    "assert \"movie_id\" in B_df.columns\n",
    "assert \"movie_id\" in C_df.columns\n",
    "assert \"movie_id\" in D_df.columns\n",
    "assert \"movie_id\" in E_df.columns\n",
    "assert \"movie_id\" in F_df.columns\n",
    "assert \"movie_id\" in G_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63eaf5-b3fe-4166-93c7-7477a3c38748",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO ->    Algunos administradores de base de datos no comprenden el uso de los joins de tipo left_semi y left_anti, por lo tanto el cliente ha solicitado que tambien se realicen las transformaciones con cualquiera de los siguientes tipos de join: **left, right, inner, outer** (no utilizar left_semi o left_anti). Podrías utilizar la transformación filter/where en algunos casos.\n",
    "##### No existe alguna reestricción de qué columnas contiene el dataframe de salida.\n",
    "- ##### Los dataframes resultantes se almacenarán en las siguientes variables:\n",
    "    - ##### A_df -> Conjunto A\n",
    "    - ##### B_df -> Conjunto B\n",
    "    - ##### C_df -> Conjunto C\n",
    "    - ##### D_df -> Conjunto D\n",
    "    - ##### E_df -> Conjunto E\n",
    "    - ##### F_df -> Conjunto F\n",
    "    - ##### G_df -> Conjunto G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35df75-5f96-4721-b9e2-1ae9d42f9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "# Conjunto A:\n",
    "A_df = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto B:\n",
    "B_df = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto C:\n",
    "C_df = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto D:\n",
    "D_df = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto E:\n",
    "E_df = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto F:\n",
    "F_df = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "\n",
    "# Conjunto G:\n",
    "G_df = ... # aplicar transformaciones join a movies_df, ratings_df y tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed8ee6-2c1e-435a-bef1-c617303b95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "assert A_df.count() == 0\n",
    "assert B_df.count() == 4270\n",
    "assert C_df.count() == 539\n",
    "assert D_df.count() == 28815\n",
    "assert E_df.count() == 2759\n",
    "assert F_df.count() == 2251\n",
    "assert G_df.count() == 47903"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2a8be-795b-4217-b5ff-663d8ba63778",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO ->    Con operaciones join genera un dataframe que contenga la union de todos los conjuntos (desde el A hasta el G) sin repetir registros. No utilices las transformaciones de union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc418dd-8cd1-4803-a439-0e7e5cf59437",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "universe_df = # aplicar transformaciones join a movies_df, ratings_df y tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc3bdb-d072-4a6b-bf85-eef22ce25394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "universe_df.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida:\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|movie_id|               title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|  100062|My Way (Mai Wei) ...|[Action, Drama, War]|2011|      3.63|         0.83|          64|2014-03-11 21:23:33|[{PRESS-GANGED, 1...|2018-05-26 16:40:54|\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dfa01-26a2-48bc-ac05-aa5d660f3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "data = [Row(\n",
    "    movie_id='100062', \n",
    "    title='My Way (Mai Wei) (2011)', \n",
    "    genres=['Action', 'Drama', 'War'], \n",
    "    year=2011, \n",
    "    avg_rating=3.63, \n",
    "    stddev_rating=0.83, \n",
    "    count_rating=64, \n",
    "    min_time_rating=datetime.datetime(2014, 3, 11, 21, 23, 33), \n",
    "    tag_count=[\n",
    "        Row(tag='FATE', count=1),\n",
    "        Row(tag='PRESS-GANGED', count=1),\n",
    "        Row(tag='WAR', count=1),\n",
    "        Row(tag='WORLD WAR II', count=1)],\n",
    "    min_time_tag=datetime.datetime(2018, 5, 26, 16, 40, 54))]\n",
    "schema = t.StructType([\n",
    "    t.StructField(\"movie_id\", t.StringType()),\n",
    "    t.StructField(\"title\", t.StringType()),\n",
    "    t.StructField(\"genres\", t.ArrayType(t.StringType())),\n",
    "    t.StructField(\"year\", t.IntegerType()),\n",
    "    t.StructField(\"avg_rating\", t.DoubleType()),\n",
    "    t.StructField(\"stddev_rating\", t.DoubleType()),\n",
    "    t.StructField(\"count_rating\", t.LongType()),\n",
    "    t.StructField(\"min_time_rating\", t.TimestampType()),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType([\n",
    "        t.StructField(\"tag\", t.StringType()),\n",
    "        t.StructField(\"count\", t.LongType())\n",
    "    ]))),\n",
    "    t.StructField(\"min_time_tag\", t.TimestampType())\n",
    "])\n",
    "expected_df = spark.createDataFrame(data, schema)\n",
    "expected_columns = [\"movie_id\", \"title\", \"genres\", \"year\",\n",
    "                    \"avg_rating\", \"stddev_rating\", \"count_rating\",\n",
    "                    \"min_time_rating\", \"tag_count\", \"min_time_tag\"]\n",
    "\n",
    "assert universe_df.count() == 86537\n",
    "assert set(universe_df.columns) - set(expected_columns) == set()\n",
    "assert set(expected_columns) - set(universe_df.columns) == set()\n",
    "assert universe_df \\\n",
    "    .select(*expected_columns) \\\n",
    "    .filter(f.col(\"movie_id\") == \"100062\") \\\n",
    "    .subtract(expected_df).count() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc31f99-4163-4721-b33d-b1ecdc8d4b05",
   "metadata": {},
   "source": [
    "#### Actividad 4:\n",
    "##### TO DO ->    La estructura del dataframe final de acuerdo al análisis realizado por marketing es el dado por la union del conjunto de datos: A, D, E y G. Realiza este proceso y almacena el dataframe resultante en la variable \"final_df\"\n",
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835c048-f0fd-455e-8f2e-725575e9c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "final_df = # aplicar transformaciones join a movies_df, ratings_df y tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cade6f4-ba10-47be-a2e9-f37e0f1ebbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "final_df.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida:\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|movie_id|           title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|       1|Toy Story (1995)|[Adventure, Anima...|1995|      3.89|         0.93|       76813|1996-01-28 18:00:00|[{TIME TRAVEL, 11...|2006-01-12 19:19:35|\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f51d7-33e5-4e89-9781-6402060cb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "data = [Row(\n",
    "    movie_id='100062', \n",
    "    title='My Way (Mai Wei) (2011)', \n",
    "    genres=['Action', 'Drama', 'War'], \n",
    "    year=2011, \n",
    "    avg_rating=3.63, \n",
    "    stddev_rating=0.83, \n",
    "    count_rating=64, \n",
    "    min_time_rating=datetime.datetime(2014, 3, 11, 21, 23, 33), \n",
    "    tag_count=[\n",
    "        Row(tag='FATE', count=1),\n",
    "        Row(tag='PRESS-GANGED', count=1),\n",
    "        Row(tag='WAR', count=1),\n",
    "        Row(tag='WORLD WAR II', count=1)],\n",
    "    min_time_tag=datetime.datetime(2018, 5, 26, 16, 40, 54))]\n",
    "schema = t.StructType([\n",
    "    t.StructField(\"movie_id\", t.StringType()),\n",
    "    t.StructField(\"title\", t.StringType()),\n",
    "    t.StructField(\"genres\", t.ArrayType(t.StringType())),\n",
    "    t.StructField(\"year\", t.IntegerType()),\n",
    "    t.StructField(\"avg_rating\", t.DoubleType()),\n",
    "    t.StructField(\"stddev_rating\", t.DoubleType()),\n",
    "    t.StructField(\"count_rating\", t.LongType()),\n",
    "    t.StructField(\"min_time_rating\", t.TimestampType()),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType([\n",
    "        t.StructField(\"tag\", t.StringType()),\n",
    "        t.StructField(\"count\", t.LongType())\n",
    "    ]))),\n",
    "    t.StructField(\"min_time_tag\", t.TimestampType())\n",
    "])\n",
    "expected_df = spark.createDataFrame(data, schema)\n",
    "\n",
    "expected_columns = [\"movie_id\", \"title\", \"genres\", \"year\",\n",
    "                    \"avg_rating\", \"stddev_rating\", \"count_rating\",\n",
    "                    \"min_time_rating\", \"tag_count\", \"min_time_tag\"]\n",
    "\n",
    "assert final_df.count() == 79477\n",
    "\n",
    "assert set(final_df.columns) - set(expected_columns) == set()\n",
    "assert set(expected_columns) - set(final_df.columns) == set()\n",
    "assert final_df \\\n",
    "    .select(*expected_columns) \\\n",
    "    .filter(f.col(\"movie_id\") == \"100062\") \\\n",
    "    .subtract(expected_df).count() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20399c4b-106f-4696-b246-40f949628469",
   "metadata": {},
   "source": [
    "#### Actividad 5:\n",
    "##### TO DO ->    El cliente nos ha solicitado llenar los valores \"null\" de la columna \"year\", para esto nos ha pedido seguir la siguiente regla:\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_rating\" es null colocar el año de la columna \"min_time_tag\".\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_tag\" es null colocar el año de la columna \"min_time_rating\".\n",
    "- ##### Si la columna \"year\" es null, y las columnas \"min_time_rating\" y \"min_time_tag\" son distintas de null colocar el año menor de las columnas \"min_time_rating\" y \"min_time_tag\", en caso de que el año en ambas columnas sea el mismo colocar dicho año.\n",
    "- ##### En cualquier otro caso mantener el valor entero 1970\n",
    "##### Adicional nos ha solicitado generar una columna llamada \"year_type\" con los siguientes valores:\n",
    "- ##### Si la columna \"year\" venia con un valor distinto a null, asignar el valor \"YO\"\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_rating\" es null colocar \"YT\"\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_tag\" es null colocar \"YR\"\n",
    "- ##### Si la columna \"year\" es null, y las columnas \"min_time_rating\" y \"min_time_tag\" son distintas de null:\n",
    "    - ##### Si \"min_time_rating\" es menor a \"min_time_tag\" colocar \"YR\"\n",
    "    - ##### Si \"min_time_tag\" es menor a \"min_time_rating\" colocar \"YT\"\n",
    "    - ##### Si \"min_time_tag\" es igual a \"min_time_rating\" colocar \"YRT\"\n",
    "- ##### En cualquier otro caso mantener \"YU\"\n",
    "##### Al finalizar este proceso eliminar las columnas \"min_time_rating\" y \"min_time_tag\"\n",
    "- Para resolver estos ejercicios podrías utilizar la función year -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.year.html#pyspark.sql.functions.year\n",
    "##### Este proceso se desarrollará en un método con la firma: def get_last_movies_df(df: DataFrame) -> DataFrame\n",
    "##### La estructura del dataframe de salida será:\n",
    "* |-- movie_id: string\n",
    "* |-- title: string\n",
    "* |-- avg_rating: double\n",
    "* |-- count_rating: long\n",
    "* |-- stddev_rating: double\n",
    "* |-- genres: array\n",
    "* |--- |-- element: string\n",
    "* |-- tag_count: array\n",
    "* |--- |-- element: struct\n",
    "* |--- |--- |tag: string\n",
    "* |--- |--- |count: long\n",
    "* |-- year: integer\n",
    "* |-- year_type: string\n",
    "##### NO UTILIZAR withColumn NI withColumnRenamed, ni UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae848a85-c931-4c17-bed3-6c1981573395",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA (NO UTILIZAR UDF):\n",
    "\n",
    "def get_last_movies_df(df: DataFrame) -> DataFrame:\n",
    "    return df # transformaciones a final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68252b23-7945-4b65-9994-20980eb23889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "movies_df = get_last_movies_df(final_df)\n",
    "movies_df.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada (el orden de la columnas podría ser distinto):\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "|movie_id|           title|avg_rating|count_rating|stddev_rating|              genres|           tag_count|year|year_type|\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "|       1|Toy Story (1995)|      3.89|       76813|         0.93|[Adventure, Anima...|[{1990S, 1}, {200...|1995|       YO|\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe845e-3491-4366-8759-49d8eae1b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "test_value = [Row(\n",
    "    movie_id='179479',\n",
    "    title='Samadhi Part 1: Maya, the Illusion of the Self',\n",
    "    avg_rating=4.19,\n",
    "    count_rating=8,\n",
    "    stddev_rating=0.75,\n",
    "    genres=['Documentary'],\n",
    "    tag_count=[Row(tag='EASTERN PHILOSOPHY', count=1),\n",
    "               Row(tag='MEDITATION', count=1),\n",
    "               Row(tag='METAPHYSICAL', count=1),\n",
    "               Row(tag='NEW AGE', count=1),\n",
    "               Row(tag='SPIRITUAL', count=1)],\n",
    "    year=2017,\n",
    "    year_type='YT')]\n",
    "\n",
    "expected_count_by_year_type = [\n",
    "    Row(year_type='YO', count=79235),\n",
    "    Row(year_type='YR', count=159),\n",
    "    Row(year_type='YRT', count=55),\n",
    "    Row(year_type='YT', count=28)]\n",
    "\n",
    "expected_columns = [\"movie_id\",\"title\",\"avg_rating\",\"count_rating\",\"stddev_rating\",\"genres\",\"tag_count\",\"year\",\"year_type\"]\n",
    "\n",
    "expected_schema = 'movie_id STRING,title STRING,avg_rating DOUBLE,count_rating BIGINT,stddev_rating DOUBLE,genres ARRAY<STRING>,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>>,year INT,year_type STRING'\n",
    "\n",
    "assert set(movies_df.columns) - set(expected_columns) == set()\n",
    "assert set(expected_columns) - set(movies_df.columns) == set()\n",
    "assert movies_df.filter(f.col(\"year\").isNull()).count() == 0\n",
    "assert movies_df \\\n",
    "    .select(*expected_columns) \\\n",
    "    .filter(f.col(\"movie_id\") == \"179479\") \\\n",
    "    .collect() == test_value\n",
    "assert schema_to_ddl(spark, movies_df.select(*expected_columns)) == expected_schema\n",
    "assert movies_df.groupBy(f.col(\"year_type\")).count().orderBy(f.col(\"count\").desc()).collect() == expected_count_by_year_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f87e6-bdcf-4567-a8fe-56d4f1aa36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "dfs = [(movies_df, \"06/movies\")]\n",
    "\n",
    "write_tmp_df(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76900e-7ba9-4d99-bb20-2540cca7d4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
